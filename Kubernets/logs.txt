
==> Audit <==
|---------|-----------------|----------|-------------------------------|---------|---------------------|---------------------|
| Command |      Args       | Profile  |             User              | Version |     Start Time      |      End Time       |
|---------|-----------------|----------|-------------------------------|---------|---------------------|---------------------|
| start   |                 | minikube | 177F8E1500A75F3\Administrator | v1.33.1 | 30 Jul 24 15:32 IST | 30 Jul 24 15:35 IST |
| start   | --driver=docker | minikube | 177F8E1500A75F3\Administrator | v1.33.1 | 30 Jul 24 15:34 IST | 30 Jul 24 15:35 IST |
| start   | --driver=docker | minikube | 177F8E1500A75F3\Administrator | v1.33.1 | 30 Jul 24 15:36 IST |                     |
| start   |                 | minikube | 177F8E1500A75F3\Administrator | v1.33.1 | 30 Jul 24 15:37 IST |                     |
| start   |                 | minikube | 177F8E1500A75F3\Administrator | v1.33.1 | 30 Jul 24 15:39 IST |                     |
| start   | --driver=docker | minikube | 177F8E1500A75F3\Administrator | v1.33.1 | 30 Jul 24 15:39 IST |                     |
|---------|-----------------|----------|-------------------------------|---------|---------------------|---------------------|


==> Last Start <==
Log file created at: 2024/07/30 15:39:49
Running on machine: 177f8e1500a75f3
Binary: Built with gc go1.22.1 for windows/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0730 15:39:49.412391   10856 out.go:291] Setting OutFile to fd 84 ...
I0730 15:39:49.413872   10856 out.go:338] TERM=,COLORTERM=, which probably does not support color
I0730 15:39:49.413872   10856 out.go:304] Setting ErrFile to fd 88...
I0730 15:39:49.413872   10856 out.go:338] TERM=,COLORTERM=, which probably does not support color
W0730 15:39:49.426534   10856 root.go:314] Error reading config file at C:\Users\Administrator\.minikube\config\config.json: open C:\Users\Administrator\.minikube\config\config.json: The system cannot find the file specified.
I0730 15:39:49.432542   10856 out.go:298] Setting JSON to false
I0730 15:39:49.436113   10856 start.go:129] hostinfo: {"hostname":"177f8e1500a75f3","uptime":6346,"bootTime":1722327842,"procs":221,"os":"windows","platform":"Microsoft Windows 10 Pro","platformFamily":"Standalone Workstation","platformVersion":"10.0.19045.4291 Build 19045.4291","kernelVersion":"10.0.19045.4291 Build 19045.4291","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"eaad01dd-4ce6-45e0-91b4-c992a1351d0a"}
W0730 15:39:49.436113   10856 start.go:137] gopshost.Virtualization returned error: not implemented yet
I0730 15:39:49.438330   10856 out.go:177] * minikube v1.33.1 on Microsoft Windows 10 Pro 10.0.19045.4291 Build 19045.4291
I0730 15:39:49.440372   10856 notify.go:220] Checking for updates...
I0730 15:39:49.440972   10856 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.30.0
I0730 15:39:49.441971   10856 driver.go:392] Setting default libvirt URI to qemu:///system
I0730 15:39:49.534302   10856 docker.go:122] docker version: linux-26.1.4:Docker Desktop 4.31.1 (153621)
I0730 15:39:49.542305   10856 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0730 15:39:49.805106   10856 info.go:266] docker info: {ID:630564f7-72fb-42a1-8487-186ff4b6daa1 Containers:60 ContainersRunning:42 ContainersPaused:0 ContainersStopped:18 Images:22 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:177 OomKillDisable:true NGoroutines:170 SystemTime:2024-07-30 10:09:49.783405489 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:12 KernelVersion:5.15.153.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:6216876032 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[com.docker.desktop.address=npipe://\\.\pipe\docker_cli] ExperimentalBuild:false ServerVersion:26.1.4 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:d2d58213f83a351ca8f528a95fbd145f5654e957 Expected:d2d58213f83a351ca8f528a95fbd145f5654e957} RuncCommit:{ID:v1.1.12-0-g51d5e94 Expected:v1.1.12-0-g51d5e94} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.14.1-desktop.1] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.27.1-desktop.1] map[Name:debug Path:C:\Program Files\Docker\cli-plugins\docker-debug.exe SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container Vendor:Docker Inc. Version:0.0.32] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.2] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.24] map[Name:feedback Path:C:\Program Files\Docker\cli-plugins\docker-feedback.exe SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.5] map[Name:init Path:C:\Program Files\Docker\cli-plugins\docker-init.exe SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.2.0] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:C:\Program Files\Docker\cli-plugins\docker-scout.exe SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.9.3]] Warnings:<nil>}}
I0730 15:39:49.808115   10856 out.go:177] * Using the docker driver based on existing profile
I0730 15:39:49.809084   10856 start.go:297] selected driver: docker
I0730 15:39:49.809084   10856 start.go:901] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e Memory:3000 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.30.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.30.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Administrator:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0730 15:39:49.809084   10856 start.go:912] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0730 15:39:49.825083   10856 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0730 15:39:50.120547   10856 info.go:266] docker info: {ID:630564f7-72fb-42a1-8487-186ff4b6daa1 Containers:60 ContainersRunning:42 ContainersPaused:0 ContainersStopped:18 Images:22 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:177 OomKillDisable:true NGoroutines:170 SystemTime:2024-07-30 10:09:50.082593739 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:12 KernelVersion:5.15.153.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:6216876032 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[com.docker.desktop.address=npipe://\\.\pipe\docker_cli] ExperimentalBuild:false ServerVersion:26.1.4 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:d2d58213f83a351ca8f528a95fbd145f5654e957 Expected:d2d58213f83a351ca8f528a95fbd145f5654e957} RuncCommit:{ID:v1.1.12-0-g51d5e94 Expected:v1.1.12-0-g51d5e94} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.14.1-desktop.1] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.27.1-desktop.1] map[Name:debug Path:C:\Program Files\Docker\cli-plugins\docker-debug.exe SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container Vendor:Docker Inc. Version:0.0.32] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.2] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.24] map[Name:feedback Path:C:\Program Files\Docker\cli-plugins\docker-feedback.exe SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.5] map[Name:init Path:C:\Program Files\Docker\cli-plugins\docker-init.exe SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.2.0] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:C:\Program Files\Docker\cli-plugins\docker-scout.exe SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.9.3]] Warnings:<nil>}}
I0730 15:39:50.163546   10856 cni.go:84] Creating CNI manager for ""
I0730 15:39:50.163546   10856 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0730 15:39:50.163546   10856 start.go:340] cluster config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e Memory:3000 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.30.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.30.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Administrator:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0730 15:39:50.165546   10856 out.go:177] * Starting "minikube" primary control-plane node in "minikube" cluster
I0730 15:39:50.166544   10856 cache.go:121] Beginning downloading kic base image for docker with docker
I0730 15:39:50.168559   10856 out.go:177] * Pulling base image v0.0.44 ...
I0730 15:39:50.170556   10856 preload.go:132] Checking if preload exists for k8s version v1.30.0 and runtime docker
I0730 15:39:50.170556   10856 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e in local docker daemon
I0730 15:39:50.170556   10856 preload.go:147] Found local preload: C:\Users\Administrator\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.30.0-docker-overlay2-amd64.tar.lz4
I0730 15:39:50.170556   10856 cache.go:56] Caching tarball of preloaded images
I0730 15:39:50.171545   10856 preload.go:173] Found C:\Users\Administrator\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.30.0-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0730 15:39:50.171545   10856 cache.go:59] Finished verifying existence of preloaded tar for v1.30.0 on docker
I0730 15:39:50.171545   10856 profile.go:143] Saving config to C:\Users\Administrator\.minikube\profiles\minikube\config.json ...
I0730 15:39:50.235547   10856 image.go:83] Found gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e in local docker daemon, skipping pull
I0730 15:39:50.235547   10856 cache.go:144] gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e exists in daemon, skipping load
I0730 15:39:50.235547   10856 cache.go:194] Successfully downloaded all kic artifacts
I0730 15:39:50.236590   10856 start.go:360] acquireMachinesLock for minikube: {Name:mk3f259f80712de9f83f91ad0f12658ee47ef5bf Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0730 15:39:50.236590   10856 start.go:364] duration metric: took 0s to acquireMachinesLock for "minikube"
I0730 15:39:50.236590   10856 start.go:96] Skipping create...Using existing machine configuration
I0730 15:39:50.236590   10856 fix.go:54] fixHost starting: 
I0730 15:39:50.253543   10856 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0730 15:39:50.310543   10856 fix.go:112] recreateIfNeeded on minikube: state=Running err=<nil>
W0730 15:39:50.310543   10856 fix.go:138] unexpected machine state, will restart: <nil>
I0730 15:39:50.313562   10856 out.go:177] * Updating the running docker "minikube" container ...
I0730 15:39:50.314543   10856 machine.go:94] provisionDockerMachine start ...
I0730 15:39:50.325650   10856 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0730 15:39:50.400031   10856 main.go:141] libmachine: Using SSH client type: native
I0730 15:39:50.400616   10856 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0xb0a3c0] 0xb0cfa0 <nil>  [] 0s} 127.0.0.1 64035 <nil> <nil>}
I0730 15:39:50.400616   10856 main.go:141] libmachine: About to run SSH command:
hostname
I0730 15:39:50.595921   10856 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0730 15:39:50.595921   10856 ubuntu.go:169] provisioning hostname "minikube"
I0730 15:39:50.607039   10856 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0730 15:39:50.665908   10856 main.go:141] libmachine: Using SSH client type: native
I0730 15:39:50.666920   10856 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0xb0a3c0] 0xb0cfa0 <nil>  [] 0s} 127.0.0.1 64035 <nil> <nil>}
I0730 15:39:50.666920   10856 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0730 15:39:50.909240   10856 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0730 15:39:50.924165   10856 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0730 15:39:50.997606   10856 main.go:141] libmachine: Using SSH client type: native
I0730 15:39:50.997606   10856 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0xb0a3c0] 0xb0cfa0 <nil>  [] 0s} 127.0.0.1 64035 <nil> <nil>}
I0730 15:39:50.997606   10856 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0730 15:39:51.200578   10856 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0730 15:39:51.200578   10856 ubuntu.go:175] set auth options {CertDir:C:\Users\Administrator\.minikube CaCertPath:C:\Users\Administrator\.minikube\certs\ca.pem CaPrivateKeyPath:C:\Users\Administrator\.minikube\certs\ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:C:\Users\Administrator\.minikube\machines\server.pem ServerKeyPath:C:\Users\Administrator\.minikube\machines\server-key.pem ClientKeyPath:C:\Users\Administrator\.minikube\certs\key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:C:\Users\Administrator\.minikube\certs\cert.pem ServerCertSANs:[] StorePath:C:\Users\Administrator\.minikube}
I0730 15:39:51.200578   10856 ubuntu.go:177] setting up certificates
I0730 15:39:51.200578   10856 provision.go:84] configureAuth start
I0730 15:39:51.211577   10856 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0730 15:39:51.274578   10856 provision.go:143] copyHostCerts
I0730 15:39:51.274578   10856 exec_runner.go:144] found C:\Users\Administrator\.minikube/ca.pem, removing ...
I0730 15:39:51.274578   10856 exec_runner.go:203] rm: C:\Users\Administrator\.minikube\ca.pem
I0730 15:39:51.274578   10856 exec_runner.go:151] cp: C:\Users\Administrator\.minikube\certs\ca.pem --> C:\Users\Administrator\.minikube/ca.pem (1099 bytes)
I0730 15:39:51.275589   10856 exec_runner.go:144] found C:\Users\Administrator\.minikube/cert.pem, removing ...
I0730 15:39:51.275589   10856 exec_runner.go:203] rm: C:\Users\Administrator\.minikube\cert.pem
I0730 15:39:51.275589   10856 exec_runner.go:151] cp: C:\Users\Administrator\.minikube\certs\cert.pem --> C:\Users\Administrator\.minikube/cert.pem (1139 bytes)
I0730 15:39:51.276575   10856 exec_runner.go:144] found C:\Users\Administrator\.minikube/key.pem, removing ...
I0730 15:39:51.277574   10856 exec_runner.go:203] rm: C:\Users\Administrator\.minikube\key.pem
I0730 15:39:51.277766   10856 exec_runner.go:151] cp: C:\Users\Administrator\.minikube\certs\key.pem --> C:\Users\Administrator\.minikube/key.pem (1675 bytes)
I0730 15:39:51.278287   10856 provision.go:117] generating server cert: C:\Users\Administrator\.minikube\machines\server.pem ca-key=C:\Users\Administrator\.minikube\certs\ca.pem private-key=C:\Users\Administrator\.minikube\certs\ca-key.pem org=Administrator.minikube san=[127.0.0.1 192.168.49.2 localhost minikube]
I0730 15:39:51.393669   10856 provision.go:177] copyRemoteCerts
I0730 15:39:51.406667   10856 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0730 15:39:51.414698   10856 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0730 15:39:51.472250   10856 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:64035 SSHKeyPath:C:\Users\Administrator\.minikube\machines\minikube\id_rsa Username:docker}
I0730 15:39:51.605601   10856 ssh_runner.go:362] scp C:\Users\Administrator\.minikube\machines\server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0730 15:39:51.653587   10856 ssh_runner.go:362] scp C:\Users\Administrator\.minikube\certs\ca.pem --> /etc/docker/ca.pem (1099 bytes)
I0730 15:39:51.700153   10856 ssh_runner.go:362] scp C:\Users\Administrator\.minikube\machines\server.pem --> /etc/docker/server.pem (1196 bytes)
I0730 15:39:51.734729   10856 provision.go:87] duration metric: took 534.1508ms to configureAuth
I0730 15:39:51.734729   10856 ubuntu.go:193] setting minikube options for container-runtime
I0730 15:39:51.735324   10856 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.30.0
I0730 15:39:51.747546   10856 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0730 15:39:51.823462   10856 main.go:141] libmachine: Using SSH client type: native
I0730 15:39:51.823462   10856 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0xb0a3c0] 0xb0cfa0 <nil>  [] 0s} 127.0.0.1 64035 <nil> <nil>}
I0730 15:39:51.823462   10856 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0730 15:39:52.070779   10856 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0730 15:39:52.070779   10856 ubuntu.go:71] root file system type: overlay
I0730 15:39:52.070779   10856 provision.go:314] Updating docker unit: /lib/systemd/system/docker.service ...
I0730 15:39:52.083841   10856 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0730 15:39:52.176561   10856 main.go:141] libmachine: Using SSH client type: native
I0730 15:39:52.176561   10856 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0xb0a3c0] 0xb0cfa0 <nil>  [] 0s} 127.0.0.1 64035 <nil> <nil>}
I0730 15:39:52.176561   10856 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0730 15:39:52.401268   10856 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0730 15:39:52.413259   10856 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0730 15:39:52.480258   10856 main.go:141] libmachine: Using SSH client type: native
I0730 15:39:52.480258   10856 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0xb0a3c0] 0xb0cfa0 <nil>  [] 0s} 127.0.0.1 64035 <nil> <nil>}
I0730 15:39:52.480258   10856 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0730 15:39:52.672388   10856 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0730 15:39:52.672388   10856 machine.go:97] duration metric: took 2.3578454s to provisionDockerMachine
I0730 15:39:52.672388   10856 start.go:293] postStartSetup for "minikube" (driver="docker")
I0730 15:39:52.672388   10856 start.go:322] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0730 15:39:52.686225   10856 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0730 15:39:52.693434   10856 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0730 15:39:52.775649   10856 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:64035 SSHKeyPath:C:\Users\Administrator\.minikube\machines\minikube\id_rsa Username:docker}
I0730 15:39:52.934540   10856 ssh_runner.go:195] Run: cat /etc/os-release
I0730 15:39:52.943183   10856 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0730 15:39:52.943183   10856 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0730 15:39:52.943183   10856 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0730 15:39:52.943183   10856 info.go:137] Remote host: Ubuntu 22.04.4 LTS
I0730 15:39:52.943183   10856 filesync.go:126] Scanning C:\Users\Administrator\.minikube\addons for local assets ...
I0730 15:39:52.944239   10856 filesync.go:126] Scanning C:\Users\Administrator\.minikube\files for local assets ...
I0730 15:39:52.944331   10856 start.go:296] duration metric: took 271.9432ms for postStartSetup
I0730 15:39:52.954761   10856 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0730 15:39:52.961316   10856 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0730 15:39:53.017315   10856 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:64035 SSHKeyPath:C:\Users\Administrator\.minikube\machines\minikube\id_rsa Username:docker}
I0730 15:39:53.168857   10856 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0730 15:39:53.182123   10856 fix.go:56] duration metric: took 2.9455328s for fixHost
I0730 15:39:53.182123   10856 start.go:83] releasing machines lock for "minikube", held for 2.9455328s
I0730 15:39:53.190491   10856 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0730 15:39:53.248504   10856 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0730 15:39:53.257559   10856 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0730 15:39:53.258526   10856 ssh_runner.go:195] Run: cat /version.json
I0730 15:39:53.268292   10856 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0730 15:39:53.330774   10856 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:64035 SSHKeyPath:C:\Users\Administrator\.minikube\machines\minikube\id_rsa Username:docker}
I0730 15:39:53.331330   10856 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:64035 SSHKeyPath:C:\Users\Administrator\.minikube\machines\minikube\id_rsa Username:docker}
I0730 15:39:53.469930   10856 ssh_runner.go:195] Run: systemctl --version
I0730 15:39:53.816395   10856 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0730 15:39:53.840219   10856 ssh_runner.go:195] Run: sudo find \etc\cni\net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
W0730 15:39:53.868902   10856 start.go:438] unable to name loopback interface in configureRuntimes: unable to patch loopback cni config "/etc/cni/net.d/*loopback.conf*": sudo find \etc\cni\net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;: Process exited with status 1
stdout:

stderr:
find: '\\etc\\cni\\net.d': No such file or directory
I0730 15:39:53.890313   10856 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0730 15:39:53.914211   10856 cni.go:259] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I0730 15:39:53.914211   10856 start.go:494] detecting cgroup driver to use...
I0730 15:39:53.914211   10856 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0730 15:39:53.914805   10856 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0730 15:39:53.963009   10856 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0730 15:39:53.995119   10856 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0730 15:39:54.015123   10856 containerd.go:146] configuring containerd to use "cgroupfs" as cgroup driver...
I0730 15:39:54.026118   10856 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0730 15:39:54.065510   10856 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0730 15:39:54.094940   10856 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0730 15:39:54.120938   10856 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0730 15:39:54.154470   10856 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0730 15:39:54.194466   10856 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0730 15:39:54.234221   10856 ssh_runner.go:195] Run: sh -c "sudo sed -i '/^ *enable_unprivileged_ports = .*/d' /etc/containerd/config.toml"
I0730 15:39:54.267819   10856 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)\[plugins."io.containerd.grpc.v1.cri"\]|&\n\1  enable_unprivileged_ports = true|' /etc/containerd/config.toml"
I0730 15:39:54.300061   10856 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0730 15:39:54.330513   10856 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0730 15:39:54.353510   10856 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0730 15:39:54.522949   10856 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0730 15:39:54.728796   10856 start.go:494] detecting cgroup driver to use...
I0730 15:39:54.728886   10856 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0730 15:39:54.738205   10856 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0730 15:39:54.775575   10856 cruntime.go:279] skipping containerd shutdown because we are bound to it
I0730 15:39:54.789598   10856 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0730 15:39:54.815497   10856 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0730 15:39:54.857006   10856 ssh_runner.go:195] Run: which cri-dockerd
I0730 15:39:54.877622   10856 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0730 15:39:54.892995   10856 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0730 15:39:54.941781   10856 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0730 15:39:55.126120   10856 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0730 15:39:55.303617   10856 docker.go:574] configuring docker to use "cgroupfs" as cgroup driver...
I0730 15:39:55.303617   10856 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (130 bytes)
I0730 15:39:55.364530   10856 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0730 15:39:55.595799   10856 ssh_runner.go:195] Run: sudo systemctl restart docker
I0730 15:39:56.341202   10856 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.socket
I0730 15:39:56.370526   10856 ssh_runner.go:195] Run: sudo systemctl stop cri-docker.socket
I0730 15:39:56.403295   10856 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0730 15:39:56.430265   10856 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0730 15:39:56.583372   10856 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0730 15:39:56.745644   10856 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0730 15:39:56.911347   10856 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0730 15:39:56.957244   10856 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0730 15:39:56.993128   10856 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0730 15:39:57.167424   10856 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.service
I0730 15:39:57.414919   10856 start.go:541] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0730 15:39:57.423878   10856 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0730 15:39:57.433588   10856 start.go:562] Will wait 60s for crictl version
I0730 15:39:57.442575   10856 ssh_runner.go:195] Run: which crictl
I0730 15:39:57.459607   10856 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0730 15:39:57.598134   10856 start.go:578] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  26.1.1
RuntimeApiVersion:  v1
I0730 15:39:57.606108   10856 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0730 15:39:57.691806   10856 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0730 15:39:57.748679   10856 out.go:204] * Preparing Kubernetes v1.30.0 on Docker 26.1.1 ...
I0730 15:39:57.757266   10856 cli_runner.go:164] Run: docker exec -t minikube dig +short host.docker.internal
I0730 15:39:57.926405   10856 network.go:96] got host ip for mount in container by digging dns: 192.168.65.254
I0730 15:39:57.936414   10856 ssh_runner.go:195] Run: grep 192.168.65.254	host.minikube.internal$ /etc/hosts
I0730 15:39:57.961332   10856 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0730 15:39:58.015330   10856 kubeadm.go:877] updating cluster {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e Memory:3000 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.30.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.30.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Administrator:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s} ...
I0730 15:39:58.015330   10856 preload.go:132] Checking if preload exists for k8s version v1.30.0 and runtime docker
I0730 15:39:58.026329   10856 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0730 15:39:58.065642   10856 docker.go:685] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.30.0
registry.k8s.io/kube-scheduler:v1.30.0
registry.k8s.io/kube-controller-manager:v1.30.0
registry.k8s.io/kube-proxy:v1.30.0
registry.k8s.io/etcd:3.5.12-0
registry.k8s.io/coredns/coredns:v1.11.1
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0730 15:39:58.066638   10856 docker.go:615] Images already preloaded, skipping extraction
I0730 15:39:58.073652   10856 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0730 15:39:58.131094   10856 docker.go:685] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.30.0
registry.k8s.io/kube-scheduler:v1.30.0
registry.k8s.io/kube-controller-manager:v1.30.0
registry.k8s.io/kube-proxy:v1.30.0
registry.k8s.io/etcd:3.5.12-0
registry.k8s.io/coredns/coredns:v1.11.1
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0730 15:39:58.131094   10856 cache_images.go:84] Images are preloaded, skipping loading
I0730 15:39:58.131094   10856 kubeadm.go:928] updating node {  8443 v1.30.0 docker true true} ...
I0730 15:39:58.131094   10856 kubeadm.go:940] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.30.0/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=

[Install]
 config:
{KubernetesVersion:v1.30.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:}
I0730 15:39:58.139303   10856 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0730 15:39:58.305100   10856 cni.go:84] Creating CNI manager for ""
I0730 15:39:58.305178   10856 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0730 15:39:58.305282   10856 kubeadm.go:84] Using pod CIDR: 10.244.0.0/16
I0730 15:39:58.305282   10856 kubeadm.go:181] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress: APIServerPort:8443 KubernetesVersion:v1.30.0 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", ""]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP: CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[containerRuntimeEndpoint:unix:///var/run/cri-dockerd.sock hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0730 15:39:58.305948   10856 kubeadm.go:187] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", ""]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.30.0
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
containerRuntimeEndpoint: unix:///var/run/cri-dockerd.sock
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0730 15:39:58.317795   10856 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.30.0
I0730 15:39:58.339525   10856 binaries.go:44] Found k8s binaries, skipping transfer
I0730 15:39:58.356654   10856 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0730 15:39:58.380252   10856 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (295 bytes)
I0730 15:39:58.412708   10856 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0730 15:39:58.449481   10856 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2114 bytes)
I0730 15:39:58.491865   10856 ssh_runner.go:195] Run: grep <nil>	control-plane.minikube.internal$ /etc/hosts
I0730 15:39:58.514423   10856 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0730 15:39:58.660896   10856 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0730 15:39:58.691069   10856 certs.go:68] Setting up C:\Users\Administrator\.minikube\profiles\minikube for IP: 
I0730 15:39:58.691069   10856 certs.go:194] generating shared ca certs ...
I0730 15:39:58.691069   10856 certs.go:226] acquiring lock for ca certs: {Name:mk38b1aba3ca636999c633fc59ac7bca24a1dea0 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0730 15:39:58.692070   10856 certs.go:235] skipping valid "minikubeCA" ca cert: C:\Users\Administrator\.minikube\ca.key
I0730 15:39:58.692070   10856 certs.go:235] skipping valid "proxyClientCA" ca cert: C:\Users\Administrator\.minikube\proxy-client-ca.key
I0730 15:39:58.692070   10856 certs.go:256] generating profile certs ...
I0730 15:39:58.694066   10856 certs.go:359] skipping valid signed profile cert regeneration for "minikube-user": C:\Users\Administrator\.minikube\profiles\minikube\client.key
I0730 15:39:58.694066   10856 certs.go:616] failed to parse cert file C:\Users\Administrator\.minikube\profiles\minikube\apiserver.crt.723e0a6b: x509: cannot parse IP address of length 0
I0730 15:39:58.695057   10856 certs.go:363] generating signed profile cert for "minikube": C:\Users\Administrator\.minikube\profiles\minikube\apiserver.key.723e0a6b
I0730 15:39:58.695057   10856 crypto.go:68] Generating cert C:\Users\Administrator\.minikube\profiles\minikube\apiserver.crt.723e0a6b with IP's: [10.96.0.1 127.0.0.1 10.0.0.1 <nil>]
I0730 15:39:58.962253   10856 crypto.go:156] Writing cert to C:\Users\Administrator\.minikube\profiles\minikube\apiserver.crt.723e0a6b ...
I0730 15:39:58.962253   10856 lock.go:35] WriteFile acquiring C:\Users\Administrator\.minikube\profiles\minikube\apiserver.crt.723e0a6b: {Name:mkf0dec8fca6580e45bcd6823fa38a9d1c3cc753 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0730 15:39:58.963236   10856 crypto.go:164] Writing key to C:\Users\Administrator\.minikube\profiles\minikube\apiserver.key.723e0a6b ...
I0730 15:39:58.963236   10856 lock.go:35] WriteFile acquiring C:\Users\Administrator\.minikube\profiles\minikube\apiserver.key.723e0a6b: {Name:mk886b812fcd87b34191f6f273c1184ba8b0de71 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0730 15:39:58.964225   10856 certs.go:381] copying C:\Users\Administrator\.minikube\profiles\minikube\apiserver.crt.723e0a6b -> C:\Users\Administrator\.minikube\profiles\minikube\apiserver.crt
I0730 15:39:58.977219   10856 certs.go:385] copying C:\Users\Administrator\.minikube\profiles\minikube\apiserver.key.723e0a6b -> C:\Users\Administrator\.minikube\profiles\minikube\apiserver.key
I0730 15:39:58.981217   10856 certs.go:359] skipping valid signed profile cert regeneration for "aggregator": C:\Users\Administrator\.minikube\profiles\minikube\proxy-client.key
I0730 15:39:58.982234   10856 certs.go:484] found cert: C:\Users\Administrator\.minikube\certs\ca-key.pem (1679 bytes)
I0730 15:39:58.982234   10856 certs.go:484] found cert: C:\Users\Administrator\.minikube\certs\ca.pem (1099 bytes)
I0730 15:39:58.983237   10856 certs.go:484] found cert: C:\Users\Administrator\.minikube\certs\cert.pem (1139 bytes)
I0730 15:39:58.983237   10856 certs.go:484] found cert: C:\Users\Administrator\.minikube\certs\key.pem (1675 bytes)
I0730 15:39:58.984226   10856 ssh_runner.go:362] scp C:\Users\Administrator\.minikube\ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0730 15:39:59.031334   10856 ssh_runner.go:362] scp C:\Users\Administrator\.minikube\ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0730 15:39:59.080461   10856 ssh_runner.go:362] scp C:\Users\Administrator\.minikube\proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0730 15:39:59.118717   10856 ssh_runner.go:362] scp C:\Users\Administrator\.minikube\proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0730 15:39:59.159855   10856 ssh_runner.go:362] scp C:\Users\Administrator\.minikube\profiles\minikube\apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1407 bytes)
I0730 15:39:59.205500   10856 ssh_runner.go:362] scp C:\Users\Administrator\.minikube\profiles\minikube\apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0730 15:39:59.247660   10856 ssh_runner.go:362] scp C:\Users\Administrator\.minikube\profiles\minikube\proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0730 15:39:59.299276   10856 ssh_runner.go:362] scp C:\Users\Administrator\.minikube\profiles\minikube\proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I0730 15:39:59.334547   10856 ssh_runner.go:362] scp C:\Users\Administrator\.minikube\ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0730 15:39:59.376470   10856 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0730 15:39:59.429819   10856 ssh_runner.go:195] Run: openssl version
I0730 15:39:59.459042   10856 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0730 15:39:59.494673   10856 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0730 15:39:59.502670   10856 certs.go:528] hashing: -rw-r--r-- 1 root root 1111 Jul 30 10:05 /usr/share/ca-certificates/minikubeCA.pem
I0730 15:39:59.512669   10856 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0730 15:39:59.533669   10856 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0730 15:39:59.564162   10856 ssh_runner.go:195] Run: stat /var/lib/minikube/certs/apiserver-kubelet-client.crt
I0730 15:39:59.580804   10856 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I0730 15:39:59.602805   10856 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I0730 15:39:59.624806   10856 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I0730 15:39:59.650867   10856 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I0730 15:39:59.675449   10856 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I0730 15:39:59.697006   10856 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I0730 15:39:59.709004   10856 kubeadm.go:391] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e Memory:3000 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.30.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.30.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Administrator:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0730 15:39:59.716020   10856 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0730 15:39:59.773360   10856 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0730 15:39:59.802562   10856 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0730 15:39:59.821792   10856 kubeadm.go:213] ignoring SystemVerification for kubeadm because of docker driver
I0730 15:39:59.830581   10856 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0730 15:39:59.851929   10856 kubeadm.go:154] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0730 15:39:59.851929   10856 kubeadm.go:156] found existing configuration files:

I0730 15:39:59.865866   10856 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf
I0730 15:39:59.888458   10856 kubeadm.go:162] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/admin.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/admin.conf: No such file or directory
I0730 15:39:59.898377   10856 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/admin.conf
I0730 15:39:59.924261   10856 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf
I0730 15:39:59.938251   10856 kubeadm.go:162] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/kubelet.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/kubelet.conf: No such file or directory
I0730 15:39:59.948254   10856 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/kubelet.conf
I0730 15:39:59.979405   10856 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf
I0730 15:39:59.994407   10856 kubeadm.go:162] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/controller-manager.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/controller-manager.conf: No such file or directory
I0730 15:40:00.003406   10856 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/controller-manager.conf
I0730 15:40:00.038840   10856 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf
I0730 15:40:00.053885   10856 kubeadm.go:162] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/scheduler.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/scheduler.conf: No such file or directory
I0730 15:40:00.062841   10856 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/scheduler.conf
I0730 15:40:00.083485   10856 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.30.0:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables"
I0730 15:40:00.183528   10856 kubeadm.go:309] apiServer.certSANs: Invalid value: "": altname is not a valid IP address, DNS label or a DNS label with subdomain wildcards: a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'); a wildcard DNS-1123 subdomain must start with '*.', followed by a valid DNS subdomain, which must consist of lower case alphanumeric characters, '-' or '.' and end with an alphanumeric character (e.g. '*.example.com', regex used for validation is '\*\.[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')
I0730 15:40:00.184126   10856 kubeadm.go:309] To see the stack trace of this error execute with --v=5 or higher
W0730 15:40:00.186743   10856 out.go:239] ! initialization failed, will try again: wait: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.30.0:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables": Process exited with status 3
stdout:

stderr:
apiServer.certSANs: Invalid value: "": altname is not a valid IP address, DNS label or a DNS label with subdomain wildcards: a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'); a wildcard DNS-1123 subdomain must start with '*.', followed by a valid DNS subdomain, which must consist of lower case alphanumeric characters, '-' or '.' and end with an alphanumeric character (e.g. '*.example.com', regex used for validation is '\*\.[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')
To see the stack trace of this error execute with --v=5 or higher

I0730 15:40:00.192359   10856 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.30.0:$PATH" kubeadm reset --cri-socket /var/run/cri-dockerd.sock --force"
I0730 15:40:07.606765   10856 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.30.0:$PATH" kubeadm reset --cri-socket /var/run/cri-dockerd.sock --force": (7.4144063s)
I0730 15:40:07.620638   10856 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0730 15:40:07.643224   10856 kubeadm.go:213] ignoring SystemVerification for kubeadm because of docker driver
I0730 15:40:07.658157   10856 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0730 15:40:07.672177   10856 kubeadm.go:154] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0730 15:40:07.672177   10856 kubeadm.go:156] found existing configuration files:

I0730 15:40:07.682157   10856 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf
I0730 15:40:07.702928   10856 kubeadm.go:162] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/admin.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/admin.conf: No such file or directory
I0730 15:40:07.711925   10856 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/admin.conf
I0730 15:40:07.734925   10856 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf
I0730 15:40:07.752926   10856 kubeadm.go:162] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/kubelet.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/kubelet.conf: No such file or directory
I0730 15:40:07.762937   10856 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/kubelet.conf
I0730 15:40:07.790948   10856 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf
I0730 15:40:07.807950   10856 kubeadm.go:162] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/controller-manager.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/controller-manager.conf: No such file or directory
I0730 15:40:07.816932   10856 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/controller-manager.conf
I0730 15:40:07.840935   10856 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf
I0730 15:40:07.858932   10856 kubeadm.go:162] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/scheduler.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/scheduler.conf: No such file or directory
I0730 15:40:07.868934   10856 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/scheduler.conf
I0730 15:40:07.887365   10856 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.30.0:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables"
I0730 15:40:07.954948   10856 kubeadm.go:309] apiServer.certSANs: Invalid value: "": altname is not a valid IP address, DNS label or a DNS label with subdomain wildcards: a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'); a wildcard DNS-1123 subdomain must start with '*.', followed by a valid DNS subdomain, which must consist of lower case alphanumeric characters, '-' or '.' and end with an alphanumeric character (e.g. '*.example.com', regex used for validation is '\*\.[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')
I0730 15:40:07.954948   10856 kubeadm.go:309] To see the stack trace of this error execute with --v=5 or higher
I0730 15:40:07.956951   10856 kubeadm.go:393] duration metric: took 8.2479465s to StartCluster
I0730 15:40:07.956951   10856 cri.go:54] listing CRI containers in root : {State:all Name:kube-apiserver Namespaces:[]}
I0730 15:40:07.966952   10856 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=kube-apiserver
I0730 15:40:08.043409   10856 cri.go:89] found id: ""
I0730 15:40:08.043409   10856 logs.go:276] 0 containers: []
W0730 15:40:08.043409   10856 logs.go:278] No container was found matching "kube-apiserver"
I0730 15:40:08.043409   10856 cri.go:54] listing CRI containers in root : {State:all Name:etcd Namespaces:[]}
I0730 15:40:08.055240   10856 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=etcd
I0730 15:40:08.148545   10856 cri.go:89] found id: ""
I0730 15:40:08.148545   10856 logs.go:276] 0 containers: []
W0730 15:40:08.148545   10856 logs.go:278] No container was found matching "etcd"
I0730 15:40:08.148545   10856 cri.go:54] listing CRI containers in root : {State:all Name:coredns Namespaces:[]}
I0730 15:40:08.159131   10856 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=coredns
I0730 15:40:08.273495   10856 cri.go:89] found id: ""
I0730 15:40:08.273495   10856 logs.go:276] 0 containers: []
W0730 15:40:08.273495   10856 logs.go:278] No container was found matching "coredns"
I0730 15:40:08.273495   10856 cri.go:54] listing CRI containers in root : {State:all Name:kube-scheduler Namespaces:[]}
I0730 15:40:08.285487   10856 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=kube-scheduler
I0730 15:40:08.366294   10856 cri.go:89] found id: ""
I0730 15:40:08.366294   10856 logs.go:276] 0 containers: []
W0730 15:40:08.366294   10856 logs.go:278] No container was found matching "kube-scheduler"
I0730 15:40:08.366294   10856 cri.go:54] listing CRI containers in root : {State:all Name:kube-proxy Namespaces:[]}
I0730 15:40:08.378271   10856 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=kube-proxy
I0730 15:40:08.452559   10856 cri.go:89] found id: ""
I0730 15:40:08.452559   10856 logs.go:276] 0 containers: []
W0730 15:40:08.452559   10856 logs.go:278] No container was found matching "kube-proxy"
I0730 15:40:08.452559   10856 cri.go:54] listing CRI containers in root : {State:all Name:kube-controller-manager Namespaces:[]}
I0730 15:40:08.466316   10856 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=kube-controller-manager
I0730 15:40:08.534388   10856 cri.go:89] found id: ""
I0730 15:40:08.534388   10856 logs.go:276] 0 containers: []
W0730 15:40:08.534388   10856 logs.go:278] No container was found matching "kube-controller-manager"
I0730 15:40:08.534388   10856 cri.go:54] listing CRI containers in root : {State:all Name:kindnet Namespaces:[]}
I0730 15:40:08.543393   10856 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=kindnet
I0730 15:40:08.612846   10856 cri.go:89] found id: ""
I0730 15:40:08.612846   10856 logs.go:276] 0 containers: []
W0730 15:40:08.612846   10856 logs.go:278] No container was found matching "kindnet"
I0730 15:40:08.612846   10856 cri.go:54] listing CRI containers in root : {State:all Name:storage-provisioner Namespaces:[]}
I0730 15:40:08.626178   10856 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=storage-provisioner
I0730 15:40:08.694021   10856 cri.go:89] found id: ""
I0730 15:40:08.694021   10856 logs.go:276] 0 containers: []
W0730 15:40:08.694021   10856 logs.go:278] No container was found matching "storage-provisioner"
I0730 15:40:08.694021   10856 logs.go:123] Gathering logs for kubelet ...
I0730 15:40:08.694021   10856 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0730 15:40:08.824117   10856 logs.go:123] Gathering logs for dmesg ...
I0730 15:40:08.824117   10856 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0730 15:40:08.844113   10856 logs.go:123] Gathering logs for describe nodes ...
I0730 15:40:08.844113   10856 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.30.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0730 15:40:08.995365   10856 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.30.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.30.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0730 10:10:08.973710   17700 cert_rotation.go:168] key failed with : x509: cannot parse IP address of length 0
E0730 10:10:08.979620   17700 cert_rotation.go:168] key failed with : x509: cannot parse IP address of length 0
E0730 10:10:08.991908   17700 cert_rotation.go:168] key failed with : x509: cannot parse IP address of length 0
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0730 10:10:08.973710   17700 cert_rotation.go:168] key failed with : x509: cannot parse IP address of length 0
E0730 10:10:08.979620   17700 cert_rotation.go:168] key failed with : x509: cannot parse IP address of length 0
E0730 10:10:08.991908   17700 cert_rotation.go:168] key failed with : x509: cannot parse IP address of length 0
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0730 15:40:08.995365   10856 logs.go:123] Gathering logs for Docker ...
I0730 15:40:08.995365   10856 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0730 15:40:09.086541   10856 logs.go:123] Gathering logs for container status ...
I0730 15:40:09.086541   10856 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
W0730 15:40:09.160149   10856 out.go:364] Error starting cluster: wait: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.30.0:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables": Process exited with status 3
stdout:

stderr:
apiServer.certSANs: Invalid value: "": altname is not a valid IP address, DNS label or a DNS label with subdomain wildcards: a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'); a wildcard DNS-1123 subdomain must start with '*.', followed by a valid DNS subdomain, which must consist of lower case alphanumeric characters, '-' or '.' and end with an alphanumeric character (e.g. '*.example.com', regex used for validation is '\*\.[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')
To see the stack trace of this error execute with --v=5 or higher
W0730 15:40:09.160149   10856 out.go:239] * 
W0730 15:40:09.160894   10856 out.go:239] X Error starting cluster: wait: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.30.0:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables": Process exited with status 3
stdout:

stderr:
apiServer.certSANs: Invalid value: "": altname is not a valid IP address, DNS label or a DNS label with subdomain wildcards: a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'); a wildcard DNS-1123 subdomain must start with '*.', followed by a valid DNS subdomain, which must consist of lower case alphanumeric characters, '-' or '.' and end with an alphanumeric character (e.g. '*.example.com', regex used for validation is '\*\.[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')
To see the stack trace of this error execute with --v=5 or higher

W0730 15:40:09.162258   10856 out.go:239] * 
W0730 15:40:09.164317   10856 out.go:239] ╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│                                                                                             │
│    * If the above advice does not help, please let us know:                                 │
│      https://github.com/kubernetes/minikube/issues/new/choose                               │
│                                                                                             │
│    * Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    │
│                                                                                             │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯
I0730 15:40:09.167305   10856 out.go:177] 
W0730 15:40:09.169305   10856 out.go:239] X Exiting due to K8S_INVALID_CERT_HOSTNAME: wait: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.30.0:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables": Process exited with status 3
stdout:

stderr:
apiServer.certSANs: Invalid value: "": altname is not a valid IP address, DNS label or a DNS label with subdomain wildcards: a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'); a wildcard DNS-1123 subdomain must start with '*.', followed by a valid DNS subdomain, which must consist of lower case alphanumeric characters, '-' or '.' and end with an alphanumeric character (e.g. '*.example.com', regex used for validation is '\*\.[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')
To see the stack trace of this error execute with --v=5 or higher

W0730 15:40:09.170306   10856 out.go:239] * Suggestion: The certificate hostname provided appears to be invalid (may be a minikube bug, try 'minikube delete')
W0730 15:40:09.170306   10856 out.go:239] * Related issue: https://github.com/kubernetes/minikube/issues/9175
W0730 15:40:09.171313   10856 out.go:239] * 
W0730 15:40:09.172307   10856 out.go:239] ╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│                                                                                             │
│    * If the above advice does not help, please let us know:                                 │
│      https://github.com/kubernetes/minikube/issues/new/choose                               │
│                                                                                             │
│    * Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    │
│                                                                                             │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯
I0730 15:40:09.174308   10856 out.go:177] 


==> Docker <==
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"format\\\"\". Proceed without further sandbox information."
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=error msg="invalid key: \"format\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDformat\""
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"format\\\"\""
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=error msg="CNI failed to delete loopback network: could not retrieve port mappings: invalid key: \"format\\\"\""
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=error msg="invalid key: \"format\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDformat\""
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"format\\\"\""
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=error msg="Failed to delete corrupt checkpoint for sandbox format\": invalid key: \"format\\\"\""
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"format\\\"\". Proceed without further sandbox information."
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=error msg="invalid key: \"format\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDformat\""
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"format\\\"\""
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=error msg="CNI failed to delete loopback network: could not retrieve port mappings: invalid key: \"format\\\"\""
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=error msg="invalid key: \"format\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDformat\""
Jul 30 10:10:06 minikube cri-dockerd[16114]: time="2024-07-30T10:10:06Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"format\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Failed to delete corrupt checkpoint for sandbox format\": invalid key: \"format\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"format\\\"\". Proceed without further sandbox information."
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="invalid key: \"format\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDformat\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"format\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="CNI failed to delete loopback network: could not retrieve port mappings: invalid key: \"format\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="invalid key: \"format\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDformat\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"format\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Failed to delete corrupt checkpoint for sandbox endpoint=\"/var/run/cri-dockerd.sock\": invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\". Proceed without further sandbox information."
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="CNI failed to delete loopback network: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Failed to delete corrupt checkpoint for sandbox endpoint=\"/var/run/cri-dockerd.sock\": invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\". Proceed without further sandbox information."
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="CNI failed to delete loopback network: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Failed to delete corrupt checkpoint for sandbox endpoint=\"/var/run/cri-dockerd.sock\": invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\". Proceed without further sandbox information."
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="CNI failed to delete loopback network: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Failed to delete corrupt checkpoint for sandbox endpoint=\"/var/run/cri-dockerd.sock\": invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\". Proceed without further sandbox information."
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="CNI failed to delete loopback network: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Failed to delete corrupt checkpoint for sandbox endpoint=\"/var/run/cri-dockerd.sock\": invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\". Proceed without further sandbox information."
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="CNI failed to delete loopback network: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Failed to delete corrupt checkpoint for sandbox URL=\"unix:///var/run/cri-dockerd.sock\": invalid key: \"URL=\\\"unix:///var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Failed to delete corrupt checkpoint for sandbox URL=\"unix:///var/run/cri-dockerd.sock\": invalid key: \"URL=\\\"unix:///var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Failed to delete corrupt checkpoint for sandbox URL=\"unix:///var/run/cri-dockerd.sock\": invalid key: \"URL=\\\"unix:///var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Failed to delete corrupt checkpoint for sandbox URL=\"unix:///var/run/cri-dockerd.sock\": invalid key: \"URL=\\\"unix:///var/run/cri-dockerd.sock\\\"\""
Jul 30 10:10:07 minikube cri-dockerd[16114]: time="2024-07-30T10:10:07Z" level=error msg="Failed to delete corrupt checkpoint for sandbox URL=\"unix:///var/run/cri-dockerd.sock\": invalid key: \"URL=\\\"unix:///var/run/cri-dockerd.sock\\\"\""


==> container status <==
CONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID              POD


==> describe nodes <==
command /bin/bash -c "sudo /var/lib/minikube/binaries/v1.30.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" failed with error: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.30.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0730 10:10:26.760010   17842 cert_rotation.go:168] key failed with : x509: cannot parse IP address of length 0
E0730 10:10:26.765564   17842 cert_rotation.go:168] key failed with : x509: cannot parse IP address of length 0
The connection to the server localhost:8443 was refused - did you specify the right host or port?


==> dmesg <==
[Jul30 08:31] PCI: Fatal: No config space access function found
[  +0.030678] PCI: System does not support PCI
[  +0.064219] kvm: no hardware support
[  +0.000004] kvm: no hardware support
[  +2.075980] FS-Cache: Duplicate cookie detected
[  +0.007468] FS-Cache: O-cookie c=00000004 [p=00000002 fl=222 nc=0 na=1]
[  +0.004034] FS-Cache: O-cookie d=00000000d2d50e2c{9P.session} n=00000000cc7f4d89
[  +0.000988] FS-Cache: O-key=[10] '34323934393337353136'
[  +0.000522] FS-Cache: N-cookie c=00000005 [p=00000002 fl=2 nc=0 na=1]
[  +0.001630] FS-Cache: N-cookie d=00000000d2d50e2c{9P.session} n=00000000f3ead0ed
[  +0.001141] FS-Cache: N-key=[10] '34323934393337353136'
[  +1.871195] FS-Cache: Duplicate cookie detected
[  +0.000639] FS-Cache: O-cookie c=0000000b [p=00000002 fl=222 nc=0 na=1]
[  +0.000627] FS-Cache: O-cookie d=00000000d2d50e2c{9P.session} n=0000000029722c2a
[  +0.001296] FS-Cache: O-key=[10] '34323934393337373035'
[  +0.000484] FS-Cache: N-cookie c=0000000c [p=00000002 fl=2 nc=0 na=1]
[  +0.000847] FS-Cache: N-cookie d=00000000d2d50e2c{9P.session} n=00000000513e221f
[  +0.000858] FS-Cache: N-key=[10] '34323934393337373035'
[  +0.067549] WSL (1) ERROR: ConfigApplyWindowsLibPath:2537: open /etc/ld.so.conf.d/ld.wsl.conf
[  +0.000004]  failed 2
[  +0.008741] FS-Cache: Duplicate cookie detected
[  +0.002946] FS-Cache: O-cookie c=0000000d [p=00000002 fl=222 nc=0 na=1]
[  +0.008509] FS-Cache: O-cookie d=00000000d2d50e2c{9P.session} n=000000009b7e06e8
[  +0.001293] FS-Cache: O-key=[10] '34323934393337373133'
[  +0.001144] FS-Cache: N-cookie c=0000000e [p=00000002 fl=2 nc=0 na=1]
[  +0.001638] FS-Cache: N-cookie d=00000000d2d50e2c{9P.session} n=00000000446d5c1a
[  +0.001575] FS-Cache: N-key=[10] '34323934393337373133'
[  +0.016926] WSL (1) WARNING: /usr/share/zoneinfo/Asia/Calcutta not found. Is the tzdata package installed?
[  +0.730345] misc dxg: dxgk: dxgglobal_acquire_channel_lock: Failed to acquire global channel lock
[  +6.950264] netlink: 'init': attribute type 4 has an invalid length.
[Jul30 08:48] hrtimer: interrupt took 264247 ns


==> kernel <==
 10:10:26 up  1:39,  0 users,  load average: 1.14, 1.55, 1.11
Linux minikube 5.15.153.1-microsoft-standard-WSL2 #1 SMP Fri Mar 29 23:14:13 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.4 LTS"


==> kubelet <==
Jul 30 10:06:42 minikube kubelet[4292]: I0730 10:06:42.063227    4292 scope.go:117] "RemoveContainer" containerID="0e20a08d88c28f418e300061c4bf88552da008fe7bcebcd4c286782f1071db12"
Jul 30 10:06:42 minikube kubelet[4292]: E0730 10:06:42.063285    4292 pod_workers.go:1298] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-scheduler pod=kube-scheduler-minikube_kube-system(f9c8e1d0d74b1727abdb4b4a31d3a7c1)\"" pod="kube-system/kube-scheduler-minikube" podUID="f9c8e1d0d74b1727abdb4b4a31d3a7c1"
Jul 30 10:06:42 minikube kubelet[4292]: E0730 10:06:42.063323    4292 pod_workers.go:1298] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"etcd\" with CrashLoopBackOff: \"back-off 10s restarting failed container=etcd pod=etcd-minikube_kube-system(063d6b9688927e601f52fd818d1305c5)\"" pod="kube-system/etcd-minikube" podUID="063d6b9688927e601f52fd818d1305c5"
Jul 30 10:06:42 minikube kubelet[4292]: E0730 10:06:42.063927    4292 pod_workers.go:1298] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-apiserver\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-apiserver pod=kube-apiserver-minikube_kube-system(3c555f828409b009ebee39fdbedfcac0)\"" pod="kube-system/kube-apiserver-minikube" podUID="3c555f828409b009ebee39fdbedfcac0"
Jul 30 10:06:43 minikube kubelet[4292]: I0730 10:06:43.073415    4292 scope.go:117] "RemoveContainer" containerID="0e20a08d88c28f418e300061c4bf88552da008fe7bcebcd4c286782f1071db12"
Jul 30 10:06:43 minikube kubelet[4292]: E0730 10:06:43.074132    4292 pod_workers.go:1298] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-apiserver\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-apiserver pod=kube-apiserver-minikube_kube-system(3c555f828409b009ebee39fdbedfcac0)\"" pod="kube-system/kube-apiserver-minikube" podUID="3c555f828409b009ebee39fdbedfcac0"
Jul 30 10:06:43 minikube kubelet[4292]: W0730 10:06:43.422817    4292 reflector.go:547] object-"kube-system"/"kube-proxy": failed to list *v1.ConfigMap: Get "https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)kube-proxy&resourceVersion=367": dial tcp: lookup control-plane.minikube.internal on 192.168.65.254:53: no such host
Jul 30 10:06:43 minikube kubelet[4292]: E0730 10:06:43.422977    4292 reflector.go:150] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)kube-proxy&resourceVersion=367": dial tcp: lookup control-plane.minikube.internal on 192.168.65.254:53: no such host
Jul 30 10:06:43 minikube kubelet[4292]: I0730 10:06:43.540177    4292 scope.go:117] "RemoveContainer" containerID="b19810834dbee090f7a9af7e4ed7c72adcbdc8a1e17f9617a1cfa6b66357704b"
Jul 30 10:06:43 minikube kubelet[4292]: E0730 10:06:43.541250    4292 pod_workers.go:1298] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-scheduler pod=kube-scheduler-minikube_kube-system(f9c8e1d0d74b1727abdb4b4a31d3a7c1)\"" pod="kube-system/kube-scheduler-minikube" podUID="f9c8e1d0d74b1727abdb4b4a31d3a7c1"
Jul 30 10:06:44 minikube kubelet[4292]: I0730 10:06:44.200073    4292 scope.go:117] "RemoveContainer" containerID="a3e76e581bcd6ddf52f06f469c78ef9800d1412fd0c2598dec86975440948d45"
Jul 30 10:06:44 minikube kubelet[4292]: E0730 10:06:44.201246    4292 pod_workers.go:1298] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"etcd\" with CrashLoopBackOff: \"back-off 10s restarting failed container=etcd pod=etcd-minikube_kube-system(063d6b9688927e601f52fd818d1305c5)\"" pod="kube-system/etcd-minikube" podUID="063d6b9688927e601f52fd818d1305c5"
Jul 30 10:06:44 minikube kubelet[4292]: E0730 10:06:44.447539    4292 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/events\": dial tcp: lookup control-plane.minikube.internal on 192.168.65.254:53: no such host" event="&Event{ObjectMeta:{kube-apiserver-minikube.17e6f5a0fe3fc47c  kube-system    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Pod,Namespace:kube-system,Name:kube-apiserver-minikube,UID:3c555f828409b009ebee39fdbedfcac0,APIVersion:v1,ResourceVersion:,FieldPath:spec.containers{kube-apiserver},},Reason:Unhealthy,Message:Readiness probe failed: Get \"https://192.168.49.2:8443/readyz\": dial tcp 192.168.49.2:8443: connect: connection refused,Source:EventSource{Component:kubelet,Host:minikube,},FirstTimestamp:2024-07-30 10:06:19.32495782 +0000 UTC m=+40.370271182,LastTimestamp:2024-07-30 10:06:19.32495782 +0000 UTC m=+40.370271182,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:minikube,}"
Jul 30 10:06:44 minikube kubelet[4292]: W0730 10:06:44.591196    4292 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?resourceVersion=274": dial tcp: lookup control-plane.minikube.internal on 192.168.65.254:53: no such host
Jul 30 10:06:44 minikube kubelet[4292]: E0730 10:06:44.591395    4292 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?resourceVersion=274": dial tcp: lookup control-plane.minikube.internal on 192.168.65.254:53: no such host
Jul 30 10:06:46 minikube kubelet[4292]: I0730 10:06:46.138203    4292 scope.go:117] "RemoveContainer" containerID="7e2a70a91eb6147beb15e7d6c13741b682c0d7e8d432ca957d2423c7387ea437"
Jul 30 10:06:46 minikube kubelet[4292]: E0730 10:06:46.138837    4292 pod_workers.go:1298] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(7fd44e8d11c3e0ffe6b1825e2a1f2270)\"" pod="kube-system/kube-controller-manager-minikube" podUID="7fd44e8d11c3e0ffe6b1825e2a1f2270"
Jul 30 10:06:46 minikube kubelet[4292]: I0730 10:06:46.330797    4292 scope.go:117] "RemoveContainer" containerID="0e20a08d88c28f418e300061c4bf88552da008fe7bcebcd4c286782f1071db12"
Jul 30 10:06:46 minikube kubelet[4292]: I0730 10:06:46.412790    4292 dynamic_cafile_content.go:171] "Shutting down controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
Jul 30 10:06:46 minikube systemd[1]: Stopping kubelet: The Kubernetes Node Agent...
Jul 30 10:06:46 minikube systemd[1]: kubelet.service: Deactivated successfully.
Jul 30 10:06:46 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jul 30 10:08:08 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jul 30 10:08:08 minikube kubelet[11567]: E0730 10:08:08.764559   11567 run.go:74] "command failed" err="failed to load kubelet config file, path: /var/lib/kubelet/config.yaml, error: failed to load Kubelet config file /var/lib/kubelet/config.yaml, error failed to read kubelet config file \"/var/lib/kubelet/config.yaml\", error: open /var/lib/kubelet/config.yaml: no such file or directory"
Jul 30 10:08:08 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Jul 30 10:08:08 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Jul 30 10:08:09 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 1.
Jul 30 10:08:09 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jul 30 10:08:09 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jul 30 10:08:09 minikube kubelet[11637]: E0730 10:08:09.583580   11637 run.go:74] "command failed" err="failed to load kubelet config file, path: /var/lib/kubelet/config.yaml, error: failed to load Kubelet config file /var/lib/kubelet/config.yaml, error failed to read kubelet config file \"/var/lib/kubelet/config.yaml\", error: open /var/lib/kubelet/config.yaml: no such file or directory"
Jul 30 10:08:09 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Jul 30 10:08:09 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Jul 30 10:08:10 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jul 30 10:09:26 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jul 30 10:09:26 minikube kubelet[14009]: E0730 10:09:26.248780   14009 run.go:74] "command failed" err="failed to load kubelet config file, path: /var/lib/kubelet/config.yaml, error: failed to load Kubelet config file /var/lib/kubelet/config.yaml, error failed to read kubelet config file \"/var/lib/kubelet/config.yaml\", error: open /var/lib/kubelet/config.yaml: no such file or directory"
Jul 30 10:09:26 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Jul 30 10:09:26 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Jul 30 10:09:26 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 1.
Jul 30 10:09:26 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jul 30 10:09:26 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jul 30 10:09:27 minikube kubelet[14081]: E0730 10:09:27.045990   14081 run.go:74] "command failed" err="failed to load kubelet config file, path: /var/lib/kubelet/config.yaml, error: failed to load Kubelet config file /var/lib/kubelet/config.yaml, error failed to read kubelet config file \"/var/lib/kubelet/config.yaml\", error: open /var/lib/kubelet/config.yaml: no such file or directory"
Jul 30 10:09:27 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Jul 30 10:09:27 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Jul 30 10:09:27 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 2.
Jul 30 10:09:27 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jul 30 10:09:27 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jul 30 10:09:27 minikube systemd[1]: Stopping kubelet: The Kubernetes Node Agent...
Jul 30 10:09:27 minikube systemd[1]: kubelet.service: Deactivated successfully.
Jul 30 10:09:27 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jul 30 10:09:58 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jul 30 10:09:58 minikube kubelet[16311]: E0730 10:09:58.838076   16311 run.go:74] "command failed" err="failed to load kubelet config file, path: /var/lib/kubelet/config.yaml, error: failed to load Kubelet config file /var/lib/kubelet/config.yaml, error failed to read kubelet config file \"/var/lib/kubelet/config.yaml\", error: open /var/lib/kubelet/config.yaml: no such file or directory"
Jul 30 10:09:58 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Jul 30 10:09:58 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Jul 30 10:09:59 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 1.
Jul 30 10:09:59 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jul 30 10:09:59 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jul 30 10:09:59 minikube kubelet[16389]: E0730 10:09:59.773860   16389 run.go:74] "command failed" err="failed to load kubelet config file, path: /var/lib/kubelet/config.yaml, error: failed to load Kubelet config file /var/lib/kubelet/config.yaml, error failed to read kubelet config file \"/var/lib/kubelet/config.yaml\", error: open /var/lib/kubelet/config.yaml: no such file or directory"
Jul 30 10:09:59 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Jul 30 10:09:59 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Jul 30 10:10:00 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.

